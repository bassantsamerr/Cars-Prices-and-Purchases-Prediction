{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWbKAqSgpiUq"
      },
      "outputs": [],
      "source": [
        "from matplotlib.projections.polar import ThetaTick\n",
        "from pandas.io.parsers.python_parser import parser_defaults\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import math\n",
        "import matplotlib.pyplot as plot\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "logistic nedef"
      ],
      "metadata": {
        "id": "oc-z8fL0pjG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate hypothesis\n",
        "def hyp(x,theta):\n",
        " z = np.dot(x, theta)\n",
        " hypothesis=1.0 / (1.0 + np.exp(-z))\n",
        " return hypothesis"
      ],
      "metadata": {
        "id": "3EqV-zhl9Bqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(xtrain,ytrain,theta,lr,iterations,m):\n",
        " cost_history = [0] * iterations \n",
        " for it in range(iterations):\n",
        "      hypothesis=hyp(xtrain,theta)#calculate hypothesis function\n",
        "      \n",
        "      loss=hypothesis-ytrain #predicted output - actual output\n",
        "      gradient=(xtrain.T).dot(loss)/m \n",
        "      theta=theta - (lr*gradient)\n",
        "      cost= ((-ytrain * np.log(hypothesis) - (1 - ytrain) * np.log(1 - hypothesis)))/m\n",
        "      cost_history[it]=cost #saves each cost function value\n",
        " return theta,cost_history"
      ],
      "metadata": {
        "id": "fW05nkxQ83-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printThetas(thetas):\n",
        "    i = 0\n",
        "    for x in thetas:\n",
        "        print(\"Theta\", i, \": \", x)\n",
        "        i += 1"
      ],
      "metadata": {
        "id": "z1lP2MJU-jWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_check(pred,actual):\n",
        "    c = 0\n",
        "    for i in range(len(actual)):\n",
        "        if(pred[i]==actual[i]):\n",
        "            c+=1\n",
        "    acc = (c/len(actual))*100\n",
        "    return acc"
      ],
      "metadata": {
        "id": "maMQiQZA9em0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x,theta):\n",
        "    predict = hyp(x, theta)\n",
        "    return np.where(predict >= 0.5, 1, 0)"
      ],
      "metadata": {
        "id": "UUOz8q1iLyi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_data = pd.read_csv(\"customer_data.csv\")\n",
        "cor=customer_data.corr()\n",
        "df=pd.DataFrame(customer_data)\n",
        "df =df.sample(frac = 1)\n",
        "x = df[['age','salary']]\n",
        "y = df['purchased']\n",
        "x = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
        "x = np.hstack((np.ones((x.shape[0], 1)), x))\n",
        "x=np.array(x)\n",
        "y=np.array(y).flatten()\n",
        "theta=np.array([0, 0, 0])\n",
        "#Split the dataset into training and testing sets.\n",
        "total_rows = df.shape[0]\n",
        "train_size = int(total_rows*0.8)\n",
        "xtrain=x[0:train_size]\n",
        "ytrain=y[0:train_size]\n",
        "xtest=x[train_size:]\n",
        "ytest=y[train_size:]\n",
        "m=len(xtrain)    \n",
        "\n",
        "#calculate cost function\n",
        "#cost = (-ytrain[0] * np.log(hypothesis) - (1 - ytrain[0]) * np.log(1 - hypothesis))\n",
        "learningRate = [0.1, 0.3, 0.2, 0.05]\n",
        "i = 0\n",
        "iterations=7000\n",
        "lr = .2\n",
        "for lr in learningRate:   \n",
        "   thetas, costHistory = gradient_descent(xtrain,ytrain,theta,lr,iterations,m)\n",
        "   i += 1\n",
        "   print(\"At learning rate\", lr, \":\")\n",
        "   printThetas(thetas)\n",
        "   print(\"testing accuracy: \",accuracy_check(predict(xtest,thetas), ytest))\n",
        "   print(\"training accuracy: \",accuracy_check(predict(xtrain,thetas), ytrain))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlT59Uyipmp7",
        "outputId": "f197db21-0b90-41d3-c6f0-57410f0a8efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At learning rate 0.1 :\n",
            "Theta 0 :  -5.862361743240115\n",
            "Theta 1 :  7.560050397245029\n",
            "Theta 2 :  3.503441739896212\n",
            "testing accuracy:  92.5\n",
            "training accuracy:  83.75\n",
            "At learning rate 0.3 :\n",
            "Theta 0 :  -6.803158034735019\n",
            "Theta 1 :  8.80972468933685\n",
            "Theta 2 :  4.114730205715701\n",
            "testing accuracy:  92.5\n",
            "training accuracy:  83.4375\n",
            "At learning rate 0.2 :\n",
            "Theta 0 :  -6.592439924079017\n",
            "Theta 1 :  8.529224339876974\n",
            "Theta 2 :  3.978613030302476\n",
            "testing accuracy:  92.5\n",
            "training accuracy:  83.75\n",
            "At learning rate 0.05 :\n",
            "Theta 0 :  -4.782966934545449\n",
            "Theta 1 :  6.130600174020273\n",
            "Theta 2 :  2.794532895567688\n",
            "testing accuracy:  92.5\n",
            "training accuracy:  82.5\n"
          ]
        }
      ]
    }
  ]
}
